# Quick Start Guide

## ğŸš€ Installation & Run Instructions

### Step 1: Install Dependencies
```bash
cd your-etl-project
pip install -r requirements.txt
```

### Step 2: Run the Application
```bash
python3 run.py
```

### Step 3: Access the Application
Open your browser and visit: **http://localhost:5000**

---

## âœ… Application is Ready!

The Flask server is now running on:
- Local: http://127.0.0.1:5000
- Network: http://172.17.17.136:5000

---

## ğŸ“ First Steps

1. **Register an Account**
   - Go to http://localhost:5000
   - Click "Register here"
   - Create username, email, and password
   - Login with your credentials

2. **Create Your First ETL Job**
   
   **Option A - CSV Upload:**
   - Click "Create New Job"
   - Enter job name: "Sample Employee Data"
   - Upload `sample_data.csv` (included in the project)
   - Click "Create Job"
   
   **Option B - API Source:**
   - Click "Create New Job"
   - Enter job name: "GitHub Users"
   - Select "API Endpoint"
   - Enter URL: `https://jsonplaceholder.typicode.com/users`
   - Select format: JSON
   - Click "Create Job"

3. **Run the ETL Pipeline**
   - Click "Run ETL" button
   - Watch the pipeline extract, transform, and load your data
   - View the success message

4. **View Results**
   - Click "View Data" to see the transformed data in a table
   - Click "View Logs" to see detailed ETL execution logs

---

## ğŸ§ª Test APIs

Use these public APIs to test the system:

### JSON APIs
```
https://jsonplaceholder.typicode.com/users
https://jsonplaceholder.typicode.com/posts
https://jsonplaceholder.typicode.com/todos
https://api.github.com/users
```

### CSV APIs
```
https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv
https://people.sc.fsu.edu/~jburkardt/data/csv/airtravel.csv
```

---

## ğŸ“ Files Created Automatically

- `etl_system.db` - SQLite database (created on first run)
- `uploads/` - Folder for CSV uploads (created automatically)

---

## âœ¨ Features Demonstration

### 1. User Authentication âœ“
- Register new users
- Login/logout functionality
- Session management

### 2. Job Management âœ“
- Create jobs with CSV or API sources
- View all jobs in a list
- View detailed job information
- Delete jobs

### 3. ETL Pipeline âœ“
- **Extract**: Read CSV files or fetch from APIs
- **Transform**: Clean column names, remove empty rows
- **Load**: Save to SQLite database

### 4. Data Viewing âœ“
- View transformed data in HTML tables
- See column names and row counts
- Preview first 100 rows

### 5. Logging System âœ“
- Track extraction progress
- Monitor transformation steps
- View loading statistics
- See error messages with timestamps

---

## ğŸ¯ What Makes This MVP Complete?

âœ… **NO Dummy Code** - Every function is fully implemented  
âœ… **End-to-End Working** - Complete pipeline from source to database  
âœ… **Real ETL Operations** - Actual data extraction, transformation, and loading  
âœ… **Full CRUD** - Create, read, and delete jobs  
âœ… **Error Handling** - Comprehensive error logging and messages  
âœ… **User Management** - Complete authentication system  
âœ… **Data Visualization** - View results in formatted tables  
âœ… **Production-Ready UI** - Bootstrap 5 responsive design  
âœ… **Database Integration** - SQLAlchemy ORM with SQLite  
âœ… **File Uploads** - Secure CSV file handling  
âœ… **API Integration** - Fetch data from external APIs  

---

## ğŸ› ï¸ Tech Stack

- **Backend**: Flask 3.0.0
- **Database**: SQLite with SQLAlchemy 3.1.1
- **Authentication**: Flask-Login 0.6.3
- **Data Processing**: Pandas 2.1.3
- **HTTP Requests**: Requests 2.31.0
- **Frontend**: Bootstrap 5.3, Bootstrap Icons
- **Security**: Werkzeug password hashing

---

## ğŸ“Š Database Models

1. **Users** - User accounts
2. **Jobs** - ETL job definitions
3. **DataSources** - CSV files or API endpoints
4. **ETLRuns** - Execution history
5. **ETLLogs** - Detailed logs per run

---

## ğŸ”’ Security Features

- Password hashing with Werkzeug
- Flask-Login session management
- Secure filename handling
- URL validation for APIs
- File type validation for uploads
- User-specific job isolation

---

## ğŸš¨ Troubleshooting

**Port already in use?**
```bash
# Kill existing Flask process
pkill -f "python3 run.py"
# Then run again
python3 run.py
```

**Database locked?**
```bash
# Remove the database and restart
rm etl_system.db
python3 run.py
```

**Need to drop specific tables?**
```bash
# List all tables
sqlite3 etl_system.db ".tables"

# Drop a specific table (replace 'table_name' with actual name)
sqlite3 etl_system.db "DROP TABLE table_name;"

# Drop multiple tables in one command
sqlite3 etl_system.db "DROP TABLE table1; DROP TABLE table2;"
```

---

## ğŸ“ Support

This is a complete, fully functional ETL Management System with no placeholders or dummy code. Every feature works end-to-end!

**Enjoy building your ETL pipelines! ğŸ‰**
